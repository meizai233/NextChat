import { createOpenAI } from "@ai-sdk/openai";
import { db } from "@lib/db";
import { chatMessage } from "@lib/db/schema";
import { streamText } from "ai";
import { nanoid } from "nanoid";

// Allow streaming responses up to 30 seconds
export const maxDuration = 30;

export async function POST(req: Request) {
  // Extract the `messages` and config from the body of the request
  const { messages, id: chatSessionId, config } = await req.json();

  const userMessage = messages[messages.length - 1]; // ç”¨æˆ·å‘çš„æœ€åä¸€æ¡æ¶ˆæ¯
  console.log(config, "configggg");
  // ä½¿ç”¨ç”¨æˆ·é…ç½®åˆ›å»º OpenAI å®ä¾‹
  const openai = createOpenAI({
    apiKey: config.openaiApiKey || process.env.OPENAI_API_KEY!, // å¦‚æœç”¨æˆ·æ²¡æœ‰æä¾›ï¼Œä½¿ç”¨ç¯å¢ƒå˜é‡
    baseURL: config.openaiEndpoint || process.env.OPENAI_BASE_URL,
  });

  // Call the language model
  // å¾…åŠ streamTextæ˜¯å•¥å‘¢
  const result = streamText({
    model: openai("gpt-3.5-turbo"),
    messages,
    async onFinish({ text, toolCalls, toolResults, usage, finishReason }) {
      // implement your own logic here, e.g. for storing messages
      // or recording token usage
      console.log(text, "text");
      // ğŸ‘‡ æ’å…¥ç”¨æˆ·çš„æ¶ˆæ¯
      await db.insert(chatMessage).values({
        id: nanoid(),
        chatSessionId,
        role: "user",
        content: userMessage.content,
      });

      // ğŸ‘‡ æ’å…¥ AI çš„å›å¤
      await db.insert(chatMessage).values({
        id: nanoid(),
        chatSessionId,
        role: "assistant",
        content: text,
      });
    },
  });

  // Respond with the stream
  return result.toDataStreamResponse();
}
